\section{Data, Features, Models}

This section will mainly focus on data, features, and models.
As has been mentioned in the previous section the first key element
of machine learning is \emph{data}. Then, by processing these data,
the second main key will be extracted, the so-called \emph{features},
which are the most relevant part of the data that will be used for
learning. Finally, based on the features extracted previously, it will
be possible to build the so-called \emph{models} that will represent the
summary of the knowledge acquired through the learning process and will
be used to perform some actions.

\subsection{Learning Process}

Based on the results provided in the previous section, it is time to
introduce a more complete description of the machine learning pipeline,
as illustrated in the image below:

\vspace{5mm}

\begin{figure}[h]
      \centering
      \includegraphics[width=\textwidth]{../img/Learning_process}
      \caption{Learning process in detail}
\end{figure}

\newpage

So, as can be observed in the image above, the learning process
in real-world applications where some kind of machine learning is
used is actually quite complex and it is also necessary to understand
how to perform each step of the pipeline shown below in order to build
an actually working machine learning model:

\begin{enumerate}
      \item \emph{\textbf{Data Source}}: This is the actual place where
            all data are generated. Normally this place is represented
            by the real world itself.
      \item \emph{\textbf{Data Collecting}}: This is the process by which
            all data are collected from the data source mentioned in
            point 1 by using different devices, such as
            \underline{sensors}, cameras, and databases.
      \item \emph{\textbf{Data Preprocessing}}: This is a process that
            depends on the type of the problem which is being addressed.
            Normally this process consists in some noise filtering, if the
            data are images or sensor signals, in normalization,
            if the data are seen as vectors, or in the
            so-called \emph{feature extraction}, which is achieved by
            transforming the data into a set of vectors containing relevant
            information.
      \item \emph{\textbf{Dimensionality Reduction(Optional)}}: Sometimes
            the features from the previous step are not used directly to
            produce a model, but are carefully selected to extract
            the most relevant part through the process called \emph{feature selection}.
      \item \emph{\textbf{Model Learning}}: This is the core step of the
            machine learning process in which, by applying a particular
            \emph{learning algorithm}, the actual \emph{model}
            is generated. The actual type of algorithm that will be
            applied depends on the particular nature of the problem being
            solved, such as classification, regression, clustering,
            description, and many others.
      \item \emph{\textbf{Model Testing}}: Once the model has been
            generated through a particular learning algorithm, a
            particular model testing protocol is applied to validate
            the accuracy of the generated model.
\end{enumerate}

It is also important to mention that another element that adds complexity
to the design of machine learning models is the choice of a particular
algorithm to use. This is because of the fact that there is a huge number
of machine learning algorithms that could be used. Fortunately, there is
always a guide that helps in making the right decision, that is the
particular nature of the problem to be solved.

At this point, given the general machine learning pipeline described
above, it is time to dive into each step of the process by starting
with the first most important element which is \emph{data}. The first
problem to solve is the fact that the concept of data is quite abstract,
but the concrete data that are used in real-world applications can be
extremely different form each other. For this reason, it is necessary to
define a general procedure that will allow representing data
independently of their actual structure. The answer to this problem is
called \emph{feature extraction}: that is the process by which each
\emph{example} in the \emph{training set} is associated with a data
structure, which is normally a simple vector of numbers with cardinality
n, that \emph{represents} the relevant information about the example and
indicates the \emph{actual form} that is seen by the algorithms. Each
such vector takes the name of \emph{feature}.

\newpage

One way of extracting these features is to consider them as
\emph{questions that can be asked} about the example, like for instance
in the image below with the fruits:

\vspace{5mm}

\begin{figure}[h]
      \centering
      \begin{subfigure}{0.45\textwidth}
            \centering
            \includegraphics[width=\textwidth]{../img/Features_1}
      \end{subfigure}
      \hfill
      \begin{subfigure}{0.45\textwidth}
            \centering
            \includegraphics[width=\textwidth]{../img/Features_2}
      \end{subfigure}
      \caption{Example of features}
\end{figure}

\vspace{5mm}

Therefore, the final result of the feature extraction process is the
actual \emph{training set}, which is a set of numerical vectors, each of
which is the same dimension as the others. Unfortunately, there is a
problem with this approach, which is actually the most delicate part of
the design of the machine learning pipeline: \emph{how} are these
features chosen? There are actually many answers to this question and
the best answer should be the one that will ideally produce a set of
features that represent as well as possible the original data without
any loss of information. Therefore, there is always a risk that, after
processing the input data,
\underline{some information associated with the real data may be lost},
which in the case could cause the machine learning algorithm to work
improperly.